---
title: "Meta-analysis"
output: github_document
---
## R packages

1) meta: standard methods for meta-analysis 
2) metasens: Advanced methods to model and adjust for bias in meta-analysis
3) metafor: general package for meta-analysis, provides methods for multilevel meta-analysis + multivariate
4) netmeta: frequentist method for network meta=analysis

## Standard pair-wise meta-analysis

- assumption test: heterogeneity within each direct comparison 

## Network meta-analysis

- simultaneously compare between any pairs of interventions in the network.--> enables the *relative ranking* for a given outcome 
- available both direct and indirect intervention comparisons
- assume that the amount of heterogeneity is the same for every comparison in the network
- outcome: Ranking probability, such as the mean ranks, median ranks and the cumulative ranking probabilities
** indirect intervention: estimate the relative effect of two interventions when no studies have compared. two assumptions; 1) notion of transitivity 2) coherence

** transitivity: the average of all important factors should be similar in different sets of randomized trials 
** coherence(consistency): different sources agree with each other
** confounding: complicates interpretation of subgroup analysis and meta-regressions and lead to incorrect conclusion
** pooled variance: common variance when different populations have the same variance, check the similarity, use ratio of sample standard deviation
## desing of Cochrane Review with multiple interventions 
1) population
2) interventions
## statistical methods
### hierarchical models
can be found in WinBUGS and OpenBUGS.
### Multivariate meta-analysis methods
**  the heterogeneity among studies in the network as a whole is larger than the heterogeneity within the direct comparison, and therefore some uncertainty is added in the network estimates
** Odds ratios lower than 1 favour the column-defining intervention 
```{r}
# import data
library(meta)
library(metasens)
joy <- read.csv("Data/ebmental_2019.txt")
# manipulate data
joy$miss = ifelse((joy$drop.h + joy$drop.p) == 0, "Without missing data", "With missing data") 
head(joy)
```
- responded in the haloperidol arm (resp.h) == true positive</br>
- responded in the placebo arm (resp.p) == false positive</br>
- failed to respond in the haloperidol arm (fail.h)  == true negative</br>
- failed to respond in the placebo arm (fail.p). == false negative</br>
- who dropped out, for which the outcome is missing, in either arm (drop.h, drop.p)


## Fixed effect and random effects meta-analysis
```{r}
# print results with two significant digits
settings.meta(digits = 2) 
m.publ = metabin(resp.h, resp.h + fail.h , resp.p, resp.p + fail.p, 
                data = joy, 
                studlab = paste0(author, "(", year, ")"), 
                method.tau = "PM" )
m.publ
```
method is used to estimate the confidence interval of τ^2 and ==  estimate the between-study variance in the random effects model </br>
- method.tau = "DL", "PM(Paule-Mandel estimator)", "REML", "ML", "HS", "SJ", "HE", or "EB",

measures of treatment effect</br>
- sm = "RR"(Risk ratio), "OR"(Odds ratio), "RD"(Risk difference), "ASD"(Arcsien difference), or "DOR"(Diagnostic Odds ratio)
- allincr = True , if at least one study has a zero cell count

method used for pooling == method to calculate the fixed effect estimate</br>
- method = "Inverse"(inverse variance weighting), "MH(Mantel-Haenszel)", "Peto", "GLMM"(generalised linear mixed model), or "SSW"(sample size method)

method to calculate a confidence interval for τ^2 and τ</br>
- method.tau.ci = "J"(Jackson),"BJ"(Biggerstaff and Jackson),"QP"(Q-profile method)</br>

--> test of heterogeneity: (p=0.004), presence of heterogeneous results
--> heterogeneity statistic I2 is 54%: indicative of moderate heterogeneity
--> its CI ranges from 21% to 74%: denoting potentially unimportant to substantial heterogeneity
--> CI from the random effects model is wider compared with the one from the fixed effect model, but differ slightly
## Forest plot
```{r}
# forest plot
forest(m.publ, 
       sortvar = year, 
       prediction = TRUE , #  prediction interval shown
       label.left = "Favo u rs placebo" , label.right = "Favo u rs haloperidol" )
#help(forest.meta)
```
--> diamond: estimated RRs and CI do not cross the line of no effect --> haloperidol is significantly more effective than placebo
--> cross the line of no effect: placebo might be superiod to haloperidol in a future study
## Subgroup analysis: impact of missing data
```{r}
m.publ.sub = update(m.publ, byvar = miss, print.byvar = FALSE ) # group by 'miss' add new variable 'miss'
m.publ.sub
forest(m.publ.sub, 
       sortvar = year, 
       prediction = TRUE , #  prediction interval shown
       label.left = "Favo u rs placebo" , label.right = "Favo u rs haloperidol" )
forest(m.publ.sub, 
       sortvar = year,
       xlim = c(0.1, 100), at = c(0.1, 0.3, 1, 3, 10, 30, 100),
       test.subgroup.random = TRUE)
```
--> studies without missing data report a larger haloperidol effect compared with the studies with missing data</br>
--> subgroup differece test test under the random effects model: missing data might have some impact on the results (p=0.03)∂

## Sensitivity analysis for missing binary outcomes
to adjust the effect estimate for this bias
```{r}
mmiss.1 = metamiss (m.publ, drop.h, drop.p, method.miss = "1" ) # missing value as 1
mmiss.1
#help(metamiss)
```
- method: "GH", "IMOR", "0", "1", "pc", "pe", "p", "b", or "w"
- small.values: small treatment effects indicate a beneficial ("good") or harmful ("bad") effect
```{r}
## Imputation methods for the meta-analysis of binary outcomes with missing data
# Impute as no events (ICA-0) - default
mmiss.0 = metamiss(m.publ, drop.h, drop.p)
# Impute as events (ICA-1)
mmiss.1 = metamiss(m.publ, drop.h, drop.p, method = "1")
# Observed risk in control group (ICA-pc)
mmiss.pc = metamiss(m.publ, drop.h, drop.p, method = "pc")
# Observed risk in experimental group (ICA-pe)
mmiss.pe = metamiss(m.publ, drop.h, drop.p, method = "pe")
# Observed group-specific risks (ICA-p)
mmiss.p = metamiss(m.publ, drop.h, drop.p, method = "p")
# Best-case scenario (ICA-b)
mmiss.b = metamiss(m.publ, drop.h, drop.p, method = "b", small.values = "bad")
# Worst-case scenario (ICA-w)
mmiss.w = metamiss(m.publ, drop.h, drop.p, method = "w", small.values = "bad")
# Gamble-Hollis method
mmiss.gh = metamiss(m.publ, drop.h, drop.p, method = "GH")
# Informative Missingness Odds Ratio (IMOR): odds of an event in the missing group over the odds of an event in the observed group
# IMOR.e = 2 and IMOR.c = 2: odds for an event is assumed to be twice as likely for missing observations
mmiss.imor2 = metamiss(m.publ, drop.h, drop.p, method = "IMOR", IMOR.e = 2)
# IMOR.e = 0.5 and IMOR.c = 0.5
mmiss.imor0.5 = metamiss(m.publ, drop.h, drop.p, method = "IMOR", IMOR.e = 0.5)

```

```{r}
# Label
meths = c("Available case analysis (ACA)",
          "Impute no events (ICA-0)", "Impute events (ICA-1)",
          "Observed risk in control group (ICA-pc)",
          "Observed risk in experimental group (ICA-pe)",
          "Observed group-specific risks (ICA-p)",
          "Best-case scenario (ICA-b)", "Worst-case scenario (ICA-w)",
          "Gamble-Hollis analysis",
          "IMOR.e = 2, IMOR.c = 2", "IMOR.e = 0.5, IMOR.c = 0.5")
# Use inverse-variance method for pooling (which is used for imputation methods)
m.publ.iv = update(m.publ, method = "Inverse")

# Combine results (random effects)
mbr = metabind(m.publ.iv,
               mmiss.0, mmiss.1,
               mmiss.pc, mmiss.pe, mmiss.p,
               mmiss.b, mmiss.w, mmiss.gh,
               mmiss.imor2, mmiss.imor0.5,
               name = meths, pooled = "random")
forest(mbr, xlim = c(0.25, 4),
       label.left = "Favours placebo", label.right = "Favours haloperidol",
       leftcols = "studlab", leftlab = "Meta-Analysis Method",
       type.study = "diamond",
       hetlab = "", print.Q = TRUE, fs.study = 10)
```
--> all sensitivity analyses for missing data resulted in similar results.</br>
--> there's benefits of using halloperidol over placebo

## Small-study effects
*small study effect: sometimes, small study shows larger or different treatment effect than larger studies</br>
*check asymmetry using funnel plot
```{r}
# Harbord's score test for funnel plot asymmetry
metabias(m.publ, method.bias = "score")
par(mfrow=c(2,2))

# Funnel plot
funnel(m.publ)
title(main = "Funnel plot")

# Contour-enhanced funnel plot
funnel(m.publ, xlim = c(0.05, 50),
       contour.levels = c(0.9, 0.95, 0.99),
       col.contour = c("darkgray", "gray", "lightgray"))
# legend("topright",
#        c("p < 1%", "1% < p < 5%", "5% < p < 10%", "p > 10%"),
#        fill = c("lightgray", "gray", "darkgray", "white"),xpd="NA")
title(main = "Contour-enhanced funnel plot")

# Trim-and-fill method
#summary(trimfill(m.publ))
funnel(trimfill(m.publ), legend=TRUE) # with missing studies filled in
title(main = "Trim-and-fill funnel plot")

# Limit meta-analysis
funnel(limitmeta(m.publ))
title(main = "Limit meta-analysis")
```
fixed effect model: dash-line</br>
random effect model: dotted line in centred.</br>
middle line: no effect</br>
--> funnel: both estimates are similar; They cannot be well distinguished. The funnel plot clearly looks asymmetric</br>
--> contour-enhanced funnel: publication bias seems not to be the dominant factor for the asymmetry</br> 
as most small studies with large SEs lie in the white area,  non-significant treatment estimates</br> 
--> The Harbord test: is highly significant (p<0.001), presence of small-study effects 
--> trim-and fill: add 9 studies. adjusted random effects estimate RR=1.4, non-significant treatment benefits
--> limit meta-analysis: some funnel plot asymmetry,adjusted estimate RR=1.29</br>
** RR larger than 1 meaning that haloperidol is better than placebo


