---
title: "SeaFlow instrument"
author: Dahee kim
date: July 29, 2019
output:
  html_document:
    toc: true
    toc_float: true
---

In this assignment, you will be working with data from the SeaFlow environmental flow cytometry instrument.

A flow cytometer delivers a flow of particles through capilliary. By shining lasers of different wavelengths and measuring the absorption and refraction patterns, you can determine how large the particle is and some information about its color and other properties, allowing you to detect it.

The technology was developed for medical applciations, where the particles were potential pathogens in, say, serum, and the goal was to give a diagnosis. But the technology was adapted for use in environmental science to understand microbial population profiles.

The SeaFlow instrument, developed by the Armbrust Lab at the University of Washington, is unique in that it is deployed on research vessels and takes continuous measurements of population profiles in the open ocean.

The scale of the data can be quite large, and is expected to grow significantly: A two-week cruise from one vessel can generate hundreds of gigabytes per day, and the vision is to deploy one of these instruments on not only research vessels but the commercial shipping fleet as well.

While there are a number of challenging analytics tasks associated with this data, a central task is classification of particles. Based on the optical measurements of the particle, it can be identified as one of several populations.

##Step 1: Read and summarize the data
Using R, read the file seaflow_21min.csv and get the overall counts for each category of particle. 
```{r}
library("knitr")
data <- read.csv("https://raw.githubusercontent.com/uwescience/datasci_course_materials/master/assignment5/seaflow_21min.csv")
summary(data$fsc_small)
table(data$pop)
```
- **file_id**: The data arrives in files, where each file represents a three-minute window; this field represents which file the data came from. The number is ordered by time, but is otherwise not significant.

- **time**: This is an integer representing the time the particle passed through the instrument. Many particles may arrive at the same time; time is not a key for this relation.

- **cell_id**: A unique identifier for each cell WITHIN a file. (file_id, cell_id) is a key for this relation.

- **d1, d2**: Intensity of light at the two main sensors, oriented perpendicularly. These sensors are primarily used to determine whether the particles are properly centered in the stream. Used primarily in preprocesssing; they are unlikely to be useful for classification.

- **fsc_small, fsc_perp, fsc_big**: Forward scatter small, perpendicular, and big. These values help distingish different sizes of particles.

- **pe**: A measurement of phycoerythrin fluorescence, which is related to the wavelength associated with an orange color in microorganisms

- **chl_small**, chl_big: Measurements related to the wavelength of light corresponding to chlorophyll.

##Step 2: Split the data into test and training sets
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
#install.packages("caret")
library(caret)
set.seed(3000)
trainIndex <- createDataPartition(data$pop, p = .5, 
                                  list = FALSE)
Train <- data[ trainIndex,]
Test  <- data[-trainIndex,]
summary(Train)
```

##Step 3: Plot the data
split the data into 20/80
```{r}
library(ggplot2)
ggplot(Train, aes(x=pe,y=chl_small,color=pop)) + geom_point()
ggplot(Test, aes(x=pe,y=chl_small,color=pop)) + geom_point()
```

##Step 4: Train a decision tree.
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
head(Train)
library(rpart)
fol <- formula(pop ~ fsc_small + fsc_perp + fsc_big + pe + chl_small + chl_big)
dt_model <- rpart(fol, method="class", data=Train)
print(dt_model)
```

##Step 5: Evaluate the decision tree on the test data.
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
dt_predict <- predict(dt_model, newdata=Test, type="class")
dt_result = dt_predict == Test$pop
summary(dt_result)
#0.856
```
For example, in this bogus tree, a particle with chl_small=25000 and pe=2000 would take branch 2, branch 4, and be classified as pico.
Crypto population is not recognizing. chl_small is the most important vairable in predicting the class population.

##Step 6: Build and evaluate a random forest.
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(randomForest)
rf_model <- randomForest(fol, data=Train)
rf_predict = predict(rf_model, newdata=Test)
rf_result = rf_predict == Test$pop
summary(rf_result)
importance(rf_model)
#0.9207
```
Appear most important in terms of gini impurity measure are pe and chl_small

##Step 7: Train a support vector machine model and compare results.
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(e1071)
svm_model = svm(fol, data=Train)
svm_predict = predict(svm_model, newdata=Test)
svm_result = svm_predict == Test$pop
summary(svm_result)
```
accuracy is 0.9194.

##Step 8: Construct confusion matrices
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
table(pred = dt_predict, true = Test$pop) # Decision tree
table(pred = rf_predict, true = Test$pop) # Random Forest
table(pred = svm_predict, true = Test$pop) # Support Vector Machine

plot(data$chl_big, data$chl_small)
plot(data$fsc_big, data$fsc_small)
plot(data$fsc_perp, data$pe)
```
Ultra and Pico appears to be the most common error. We assumed variables were continuous, but fsc_big has lot of clustering. 

##Step 9: Remove File 208 from the mix and run the SVM again. What's the change in accuracy?
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
newfol <- formula(pop ~ fsc_small + fsc_perp + pe + chl_big + chl_small)
data2 = subset(data, data$file_id != 208)

# Resample.
set.seed(3000)
trainIndex <- createDataPartition(data2$pop, p = .5, 
                                  list = FALSE)
Train2 <- data2[ trainIndex,]
Test2  <- data2[-trainIndex,]


library("e1071")
new_svm_model = svm(newfol, data=Train2)
new_svm_predict = predict(new_svm_model, newdata=Test2)
new_svm_result = new_svm_predict == Test2$pop
summary(new_svm_result)
```
Difference in accuracy 0.9725 - 0.9194 = 0.053
